{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch_4_digit_recognizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJD+nDWQiGqgqWI6h1Zt1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmannnn/practical_deep_learning_for_coders/blob/main/ch_4_digit_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgMqFgKfBFRp"
      },
      "source": [
        "#MNIST digit recognizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk5E00dKBLpc",
        "outputId": "94b90032-1ce7-4f90-c5e4-629252ba4247"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 74.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 372 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo6RakEdBLzX"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAqxmOKCFGv"
      },
      "source": [
        "##Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XejlgwkSCVyu"
      },
      "source": [
        "Create your own implementation of Learner from scratch, based on the training loop shown in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "sUEzjm9hCa3k",
        "outputId": "9325ae8f-1c6d-43ce-c02f-9ac782ad3b9b"
      },
      "source": [
        "# setting the path to the MNIST dataset\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afK3fbCcEGdd"
      },
      "source": [
        "# grabbing just the threes and sevens form the training set to use\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecvgBOe9KBkC"
      },
      "source": [
        "# opening the training 3's/7's and changing them to tensors\n",
        "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
        "seven_tensor = [tensor(Image.open(o)) for o in sevens]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8TU3TyJD9kq"
      },
      "source": [
        "# creating Pytorch tensors of the valid 3s and 7s\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o))\n",
        "                            for o in (path/'valid'/'3').ls()])\n",
        "\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o))\n",
        "                            for o in (path/'valid'/'7').ls()])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIJ-H0-pHR1E"
      },
      "source": [
        "# stacking three_tensor  normalize the train 3 tensor\n",
        "stacked_threes = torch.stack(three_tensor).float()/255\n",
        "\n",
        "# stack then normalize the train 7 tensor\n",
        "stacked_sevens = torch.stack(seven_tensor).float()/255\n",
        "\n",
        "# normalizing the valid 3 tensor (valid_3_tens already stacked)\n",
        "valid_3_tens = valid_3_tens.float()/255\n",
        "\n",
        "# normalizing the valid 7 tensor (valid_3_tens already stacked)\n",
        "valid_7_tens = valid_7_tens.float()/255"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGTnvu-JY0N"
      },
      "source": [
        "# changing the training rank 3 tensors to a rank 2 tensor using view\n",
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "\n",
        "# changing the testing rank 3 tensors to a rank 2 tensor using view\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GNx8wkQPEaX"
      },
      "source": [
        "# creating labels for our training data as a column vector\n",
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
        "\n",
        "# creating labels for our testing data as a column vector\n",
        "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F43ncEF3PzdY"
      },
      "source": [
        "# zipping the x, y training dataset\n",
        "dset = list(zip(train_x, train_y))\n",
        "dl = DataLoader(dset, batch_size = 256)\n",
        "\n",
        "# zipping the x, y training dataset\n",
        "valid_dset = list(zip(valid_x, valid_y))\n",
        "valid_dl = DataLoader(valid_dset, batch_size = 256)\n",
        "\n",
        "# loading training DataLoader and testing DataLoader\n",
        "ds = DataLoaders(dl, valid_dl)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-c6JwifJ5lT"
      },
      "source": [
        "# creating the neural net\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWPh7AYtMbju"
      },
      "source": [
        "# PyTorch binary optimization function? nn.BCELoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V3CNFjaztzd"
      },
      "source": [
        "dataloaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwZLZAVnLkvd"
      },
      "source": [
        "class Learner():\n",
        "  \n",
        "  def __init__(self,dataloaders,model,opt,loss):\n",
        "    self.train_dl = dataloaders[0]\n",
        "    self.valid_dl = dataloaders[1]\n",
        "    self.model = model\n",
        "    self.opt = opt(self.model.parameters(), lr = 0.01)\n",
        "    self.loss_func = loss\n",
        "\n",
        "  def batch_accuracy(self, preds, yb):\n",
        "    correct = (preds > 0.5) == yb\n",
        "    return correct.float().mean()\n",
        "\n",
        "  def validate_epoch(self):\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb, yb in self.valid_dl]\n",
        "    return round(torch.stack(accs).mean().item(), 4)\n",
        "\n",
        "  def train_epoch(self):\n",
        "    for xb, yb in self.training_dl:\n",
        "      preds = self.model(xb)\n",
        "      calculated_loss = self.loss(preds, yb * 1.0)\n",
        "      calculated_loss.backwards()\n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "\n",
        "  def fit(self, n):\n",
        "    for epoch in range(n):\n",
        "      self.train_epoch()\n",
        "      print(self.validate_epoch(), end=' ')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "iLeFWOQ-xG-c",
        "outputId": "eaa7d30a-2e3a-4337-d00b-bf54cffd8468"
      },
      "source": [
        "# testing\n",
        "test = Learner(ds, simple_net, SGD, nn.BCELoss)\n",
        "test.fit(30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-997799392cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-17d82b9df564>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataloaders, model, opt, loss)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT_0i82NCX5o"
      },
      "source": [
        "##Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPApwtCMBDEU"
      },
      "source": [
        "Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDR70wk-BL3K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}