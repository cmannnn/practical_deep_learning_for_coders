{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch_4_digit_recognizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHoo51wzwyrAG4XgNKCC2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmannnn/practical_deep_learning_for_coders/blob/main/ch_4_digit_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgMqFgKfBFRp"
      },
      "source": [
        "#MNIST digit recognizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk5E00dKBLpc",
        "outputId": "25b6d933-4c4e-4e34-abd2-537a2abca3ac"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 720 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 44.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 324 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo6RakEdBLzX"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIAqxmOKCFGv"
      },
      "source": [
        "##Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XejlgwkSCVyu"
      },
      "source": [
        "Create your own implementation of Learner from scratch, based on the training loop shown in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "sUEzjm9hCa3k",
        "outputId": "403085a3-f55c-41fa-ca0c-c2a2645dc486"
      },
      "source": [
        "# setting the path to the MNIST dataset\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afK3fbCcEGdd"
      },
      "source": [
        "# grabbing just the threes and sevens form the testing set to use\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecvgBOe9KBkC"
      },
      "source": [
        "# changing the images into tensors\n",
        "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
        "seven_tensor = [tensor(Image.open(o)) for o in sevens]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8TU3TyJD9kq"
      },
      "source": [
        "# creating Pytorch tensors of the valid 3s and 7s\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o))\n",
        "                            for o in (path/'valid'/'3').ls()])\n",
        "\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o))\n",
        "                            for o in (path/'valid'/'7').ls()])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIJ-H0-pHR1E"
      },
      "source": [
        "# stack then normalize the train 3 tensor\n",
        "stacked_threes = torch.stack(three_tensor).float()/255\n",
        "\n",
        "# stack then normalize the train 7 tensor\n",
        "stacked_sevens = torch.stack(seven_tensor).float()/255\n",
        "\n",
        "# normalizing the valid 3 tensor\n",
        "valid_3_tens = valid_3_tens.float()/255\n",
        "\n",
        "# normalizing the valid 7 tensor\n",
        "valid_7_tens = valid_7_tens.float()/255"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyGTnvu-JY0N"
      },
      "source": [
        "# changing the training rank 3 tensors to a rank 2 tensor\n",
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "\n",
        "# changing the testing rank 3 tensors to a rank 2 tensor\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT_0i82NCX5o"
      },
      "source": [
        "##Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPApwtCMBDEU"
      },
      "source": [
        "Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDR70wk-BL3K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}